{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from scipy import stats as st\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, get_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/datasets/Churn.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /datasets/Churn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.CustomerId.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates in CustomerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography unique values: ['France' 'Spain' 'Germany']\n",
      "Tenure unique values: [ 2.  1.  8.  7.  4.  6.  3. 10.  5.  9.  0. nan]\n",
      "NumOfProducts unique values: [1 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "for col in ['Geography', 'Tenure', 'NumOfProducts']:\n",
    "    print(f'{col} unique values: {data[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc3ad063590>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.Tenure.hist(bins=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc3acf6ea10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.Exited.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the dataset with 10000 records. Each record corresponds to unique customer Id number thus no duplicated raws and we have missing values only in the 'Tenure' columns. Our dependent variable is in the 'Exited' column and we may clearly see that it's unbalanced one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most likely the missing values in Tenure columns stands for the clients who don't have any deposits to define the period of maturation and this is the value to keep. we have values in the column from 0 to 10 representing the the periods of maturations with meaningfull order thus if we replace the missing values with -1 it'll separate the missing values and put it just below the shortest deposits which make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          False\n",
       "CustomerId         False\n",
       "Surname            False\n",
       "CreditScore        False\n",
       "Geography          False\n",
       "Gender             False\n",
       "Age                False\n",
       "Tenure             False\n",
       "Balance            False\n",
       "NumOfProducts      False\n",
       "HasCrCard          False\n",
       "IsActiveMember     False\n",
       "EstimatedSalary    False\n",
       "Exited             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Tenure.fillna(-1, inplace=True)\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any more explorations we should put aside the test set to avoid the leakage of information from the test set. We'll drop away the identification information like row number, customer Id or surname - they won't help in training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 10), (2500, 10))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(['Exited', 'RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "    , data['Exited'], test_size=0.25, stratify=data['Exited'], random_state=123\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5432</td>\n",
       "      <td>599</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>175235.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography Gender  Age  Tenure  Balance  NumOfProducts  \\\n",
       "5432          599     Spain   Male   51     0.0      0.0              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "5432          1               1        175235.99  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two clearly categorical feature: Geography and Gender. we can't order them so one hot encoding is the best option here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5432</td>\n",
       "      <td>599</td>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>175235.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
       "5432          599   51     0.0      0.0              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "5432               1        175235.99                  0                1   \n",
       "\n",
       "      Gender_Male  \n",
       "5432            1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=['Geography', 'Gender'], drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['Geography', 'Gender'], drop_first=True)\n",
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_for_hist = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n",
    "fig, axes = plt.subplots(2,2, figsize=(10,10))\n",
    "fig.subplots_adjust(wspace=.2, hspace=.4)\n",
    "for i, col in enumerate(col_for_hist):\n",
    "    X_train[col].hist(bins=50, ax=axes[i//2,i%2])\n",
    "    axes[i//2,i%2].set_title(col, fontweight='bold', size=12)\n",
    "    \n",
    "plt.suptitle('Histograms', fontweight='bold', size=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite possible that for the features above we should look for grouping to turn them into categories of customers. But due to the fact that we are going to work mostly with tree-based algorithms we'll leave them as they are - decision tree will split them into groups for us. For the same reason we don't need to do any scaling of the data - scaling won't affect the  tree-based models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models without taking into account the imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try three classic ML models for this task: Decision Tree, Random Forest and Logistic Regression. Next we define the global parameter grids for them and use the pipeline to scale the data before applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'max_depth': range(5, 11)\n",
    "             , 'min_impurity_decrease': [0.1 * 10**(-x) for x in range(2,5)]\n",
    "            }\n",
    "\n",
    "# Initial search was made for these parameters\n",
    "## ************* it took around 2 hours to run the notebook with this grid for me ***********\n",
    "rf_params = {'max_depth': range(7, 15)\n",
    "             , 'min_impurity_decrease': [0.1 * 10**(-x) for x in range(3,5)]\n",
    "          , 'n_estimators': range(80, 151, 10)\n",
    "            }\n",
    "\n",
    "# The smaller version of parameter grid for saving time when rerun the code, results were \n",
    "# similar but the text comments was made based on full param-grid for Random Forest\n",
    "#rf_params = {'max_depth': [7, 11, 14]\n",
    "#             , 'min_impurity_decrease': [0.1 * 10**(-x) for x in range(3,5)]\n",
    "#          , 'n_estimators': [80, 110, 150]\n",
    "#            }\n",
    "\n",
    "# Pipe (we don't need to scale indicator columns but no harm if we do)\n",
    "lr_pipe = Pipeline([('scaler', StandardScaler())\n",
    "                    , ('estimator', LogisticRegression(solver='liblinear'))])\n",
    "\n",
    "lr_pipe_params = {'estimator__C': [0.001, 0.01, 0.1, 1, 5, 10, 50, 100]\n",
    "                  , 'estimator__penalty': ['l1', 'l2']\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the optimal global parameters we'll use the scikit-learn's GridSearchCV. It rely on the cross validation technique which is better then testing on one validation set. The only minus of the function for us is that we cannot easily seed it to be certain of the same results for every go. But shouldn't be a problem because we expect our best results after taking into account the imbalance of the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def global_param_tune(X_train, y_train, clf, param_grid, cv=5, scoring='f1', verbose=0):\n",
    "    search = GridSearchCV(clf, param_grid, cv=cv, scoring=scoring, return_train_score=True)\n",
    "    search.fit(X_train, y_train)\n",
    "    if verbose == 1:\n",
    "        means = search.cv_results_['mean_test_score']\n",
    "        stds = search.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, search.cv_results_['params']):\n",
    "            print(f'CV score {mean:0.4f} (+/-{std:0.4f}) for {params}')\n",
    "    print(f'Best CV score {search.best_score_:0.3f} for parameters: {search.best_params_}')\n",
    "    return search.best_estimator_, search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll find the optimal parameters for all three models and train the tuned classifiers for later final testing. Also we'll keep the CV scores in the dataframe to choose optimal model based on cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = pd.DataFrame(columns=['Decision Tree', 'Random Forest', 'Logistic Regression']\n",
    "                         , index=['Initial Data', 'Upsampled Data', 'Downsampled Data']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score 0.563 for parameters: {'max_depth': 9, 'min_impurity_decrease': 0.0001}\n",
      "CPU times: user 2.84 s, sys: 0 ns, total: 2.84 s\n",
      "Wall time: 2.85 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0001, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dt_clf, dt_cv_scores = global_param_tune(X_train, y_train, DecisionTreeClassifier()\n",
    "                                         , dt_params, verbose=0)\n",
    "cv_scores.loc['Initial Data', 'Decision Tree'] = dt_cv_scores\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score 0.577 for parameters: {'max_depth': 14, 'min_impurity_decrease': 1e-05, 'n_estimators': 110}\n",
      "CPU times: user 10min 23s, sys: 1.57 s, total: 10min 24s\n",
      "Wall time: 10min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=1e-05, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=110,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_clf, rf_cv_scores = global_param_tune(X_train, y_train, RandomForestClassifier()\n",
    "                                       , rf_params, verbose=0)\n",
    "cv_scores.loc['Initial Data', 'Random Forest'] = rf_cv_scores\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score 0.329 for parameters: {'estimator__C': 1, 'estimator__penalty': 'l1'}\n",
      "CPU times: user 10.1 s, sys: 7.73 s, total: 17.8 s\n",
      "Wall time: 17.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('estimator',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr_pipe_clf, lr_pipe_cv_scores = global_param_tune(X_train, y_train, lr_pipe\n",
    "                                                   , lr_pipe_params, verbose=0)\n",
    "cv_scores.loc['Initial Data', 'Logistic Regression'] = lr_pipe_cv_scores\n",
    "lr_pipe_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best crossvalidation score goes to Random Forest model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to improve the models with upsampling the dataset. Unfortunately we won't be able to use GridSearchCV with upsampling (actually we could with imblearn.pipeline but I'm not sure how to downsample this way) so we'll do parameter tuning and cross_validation manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    \"\"\"\n",
    "    Upsample the data with target=1\n",
    "    features - pandas dataframe with features\n",
    "    target - pandas Series with target variable, should be binary - [0,1]\n",
    "    repeat - int, how many times to repeat samples with target=1\n",
    "    \"\"\"\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=123)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    \"\"\"\n",
    "    Downsample the data with target=0\n",
    "    features - pandas dataframe with features\n",
    "    target - pandas Series with target variable, should be binary - [0,1]\n",
    "    fraction - float should be in interval (0,1)\n",
    "    , represent fraction of samples with target=0 to keep\n",
    "    \"\"\"\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=123)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=123)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=123)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(X_train, y_train, clf, params, cv=5, up=0, down=0, scoring='f1', random_state=123):\n",
    "    \"\"\"\n",
    "    Compute the cross validation scores for\n",
    "    X_train - features\n",
    "    y_train - targets\n",
    "    clf - model\n",
    "    params - parameters for model\n",
    "    cv - integer, to specify the number of folds\n",
    "    up - times to oversample the ones\n",
    "    down - share of zeros to use\n",
    "    scoring - string with name of the scorer (standard sklearn name)\n",
    "    random_state - seed the folds\n",
    "    return array with validation scores\n",
    "    \"\"\"\n",
    "    cv = StratifiedKFold(n_splits=cv, random_state=random_state)\n",
    "    scores = []\n",
    "    scorer = get_scorer(scoring)\n",
    "    for train_fold_index, val_fold_index in cv.split(X_train, y_train):\n",
    "        \n",
    "        X_train_fold, y_train_fold = X_train.iloc[train_fold_index], y_train.iloc[train_fold_index]\n",
    "        X_val_fold, y_val_fold = X_train.iloc[val_fold_index], y_train.iloc[val_fold_index]\n",
    "        \n",
    "        if up > 0:\n",
    "            X_train_fold_mod, y_train_fold_mod = upsample(X_train_fold, y_train_fold, up)\n",
    "        elif down > 0:\n",
    "            X_train_fold_mod, y_train_fold_mod = downsample(X_train_fold, y_train_fold, down)\n",
    "        else:\n",
    "            X_train_fold_mod, y_train_fold_mod = X_train_fold, y_train_fold\n",
    "        \n",
    "        model = clf.set_params(**params).fit(X_train_fold_mod, y_train_fold_mod)\n",
    "        scores.append(scorer(model, X_val_fold, y_val_fold))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_param_tune_manual(X_train, y_train, clf, param_grid, cv=5, scoring='f1'\n",
    "                             , verbose=0, up=0, down=0, random_state=123):\n",
    "    \"\"\"\n",
    "    Find optimal parameter set for the model with specified upsample or downsample\n",
    "    X_train - features\n",
    "    y_train - targets\n",
    "    clf - model\n",
    "    param_grid - dictionary of parameters to optimize\n",
    "    cv - integer, to specify the number of folds\n",
    "    up - times to oversample the ones\n",
    "    down - share of zeros to use\n",
    "    scoring - string with name of the scorer (standard sklearn name)\n",
    "    random_state - seed the score_model function\n",
    "    return best CV score and best parameters from param_grid\n",
    "    \"\"\"\n",
    "    # create list of param combinations in param_grid\n",
    "    keys = param_grid.keys()\n",
    "    values = (param_grid[key] for key in keys)\n",
    "    params = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "    # loop through params\n",
    "    score_tracker = []\n",
    "    for param in params:\n",
    "        scores = score_model(X_train, y_train, clf, param, cv=cv\n",
    "                             , up=up, down=down, scoring=scoring, random_state=random_state)\n",
    "        score_tracker.append((scores.mean(), param))\n",
    "        # print the info if needed\n",
    "        if verbose >0:\n",
    "            print(f'CV score {scores.mean():0.4f} (+/- {scores.std():0.4f}) for {param}')\n",
    "    best_scores = sorted(score_tracker, key=lambda x: x[0], reverse=True)[0]\n",
    "    print(f'Best CV score {best_scores[0]:0.4f} for parameters: {best_scores[1]}')\n",
    "    return best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7098e185221a4fda94b5785d3ba447ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsample with up=1\n",
      "Best CV score 0.5623 for parameters: {'max_depth': 9, 'min_impurity_decrease': 0.0001}\n",
      "Upsample with up=2\n",
      "Best CV score 0.6042 for parameters: {'max_depth': 8, 'min_impurity_decrease': 0.001}\n",
      "Upsample with up=3\n",
      "Best CV score 0.5966 for parameters: {'max_depth': 7, 'min_impurity_decrease': 0.001}\n",
      "\n",
      "Best score for upsample is 0.6042 for up=2 and params: {'max_depth': 8, 'min_impurity_decrease': 0.001}\n",
      "CPU times: user 13 s, sys: 15.5 ms, total: 13 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_tracker = []\n",
    "for up in tqdm(range(1,4)):\n",
    "    print(f'Upsample with up={up}')\n",
    "    score, params = global_param_tune_manual(X_train, y_train, DecisionTreeClassifier(), dt_params, up=up)\n",
    "    score_tracker.append((up, score, params))\n",
    "dt_up, score, dt_params_up = sorted(score_tracker, key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "X_train_up, y_train_up = upsample(X_train, y_train, dt_up)\n",
    "dt_clf_up = DecisionTreeClassifier(**dt_params_up).fit(X_train_up, y_train_up)\n",
    "cv_scores.loc['Upsampled Data', 'Decision Tree'] = score\n",
    "print(f'Best score for upsample is {score:0.4f} for up={dt_up} and params: {dt_params_up}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ede9c0893864f97b1975d1f34085dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsample with up=1\n",
      "Best CV score 0.5733 for parameters: {'max_depth': 13, 'min_impurity_decrease': 1e-05, 'n_estimators': 90}\n",
      "Upsample with up=2\n",
      "Best CV score 0.6159 for parameters: {'max_depth': 11, 'min_impurity_decrease': 0.0001, 'n_estimators': 150}\n",
      "Upsample with up=3\n",
      "Best CV score 0.6214 for parameters: {'max_depth': 9, 'min_impurity_decrease': 0.0001, 'n_estimators': 90}\n",
      "\n",
      "Best score for upsample is 0.6214 for up=3 and params: {'max_depth': 9, 'min_impurity_decrease': 0.0001, 'n_estimators': 90}\n",
      "CPU times: user 33min, sys: 4.74 s, total: 33min 5s\n",
      "Wall time: 33min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_tracker = []\n",
    "for up in tqdm(range(1,4)):\n",
    "    print(f'Upsample with up={up}')\n",
    "    score, params = global_param_tune_manual(X_train, y_train, RandomForestClassifier(), rf_params, up=up)\n",
    "    score_tracker.append((up, score, params))\n",
    "rf_up, rf_score, rf_params_up = sorted(score_tracker, key=lambda x: x[1], reverse=True)[0]\n",
    "X_train_up, y_train_up = upsample(X_train, y_train, rf_up)\n",
    "rf_clf_up = RandomForestClassifier(**rf_params_up).fit(X_train_up, y_train_up)\n",
    "cv_scores.loc['Upsampled Data', 'Random Forest'] = rf_score\n",
    "print(f'Best score for upsample is {rf_score:0.4f} for up={rf_up} and params: {rf_params_up}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9144b208f6b64131bbfa43efa3ee5151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upsample with up=2\n",
      "Best CV score 0.4837 for parameters: {'estimator__C': 0.1, 'estimator__penalty': 'l2'}\n",
      "Upsample with up=3\n",
      "Best CV score 0.5127 for parameters: {'estimator__C': 0.01, 'estimator__penalty': 'l1'}\n",
      "Upsample with up=4\n",
      "Best CV score 0.5093 for parameters: {'estimator__C': 0.01, 'estimator__penalty': 'l1'}\n",
      "\n",
      "Best score for upsample is 0.5127 for up=3 and params: {'estimator__C': 0.01, 'estimator__penalty': 'l1'}\n",
      "CPU times: user 28.8 s, sys: 19.2 s, total: 48 s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_tracker = []\n",
    "for up in tqdm(range(2,5)):\n",
    "    print(f'Upsample with up={up}')\n",
    "    score, params = global_param_tune_manual(X_train, y_train, lr_pipe, lr_pipe_params, up=up)\n",
    "    score_tracker.append((up, score, params))\n",
    "lr_up, lr_score, lr_params_up = sorted(score_tracker, key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "X_train_up, y_train_up = upsample(X_train, y_train, lr_up)\n",
    "lr_clf_up = lr_pipe.set_params(**lr_params_up).fit(X_train_up, y_train_up)\n",
    "cv_scores.loc['Upsampled Data', 'Logistic Regression'] = lr_score\n",
    "print(f'Best score for upsample is {lr_score:0.4f} for up={lr_up} and params: {lr_params_up}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling helps a lot. Even Logistic Regression model scores decent 51%. But no doubt Random Forest still the best approach with almost 62% CV score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what result we can achieve with another way to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bc58775fc74d5ea6366b3b8f0047c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample with down=0.35\n",
      "Best CV score 0.5946 for parameters: {'max_depth': 8, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.40\n",
      "Best CV score 0.6063 for parameters: {'max_depth': 7, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.45\n",
      "Best CV score 0.5987 for parameters: {'max_depth': 7, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.50\n",
      "Best CV score 0.6061 for parameters: {'max_depth': 8, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.55\n",
      "Best CV score 0.5994 for parameters: {'max_depth': 10, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.60\n",
      "Best CV score 0.5935 for parameters: {'max_depth': 8, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.65\n",
      "Best CV score 0.6055 for parameters: {'max_depth': 9, 'min_impurity_decrease': 0.001}\n",
      "Downsample with down=0.70\n",
      "Best CV score 0.5887 for parameters: {'max_depth': 9, 'min_impurity_decrease': 0.001}\n",
      "\n",
      "Best score for downsample is 0.6063 for  down=0.39999999999999997 and params: {'max_depth': 7, 'min_impurity_decrease': 0.001}\n",
      "CPU times: user 22.7 s, sys: 47.5 ms, total: 22.7 s\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_tracker = []\n",
    "for down in tqdm(np.arange(0.35, 0.71, 0.05)):\n",
    "    print(f'Downsample with down={down:0.2f}')\n",
    "    score, params = global_param_tune_manual(X_train, y_train, DecisionTreeClassifier(), dt_params, down=down)\n",
    "    score_tracker.append((down, score, params))\n",
    "dt_down, dt_score, dt_params_down = sorted(score_tracker, key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "X_train_down, y_train_down = downsample(X_train, y_train, dt_down)\n",
    "dt_clf_down = DecisionTreeClassifier(**dt_params_down).fit(X_train_down, y_train_down)\n",
    "cv_scores.loc['Downsampled Data', 'Decision Tree'] = dt_score\n",
    "print(f'Best score for downsample is {dt_score:0.4f} for  down={dt_down} and params: {dt_params_down}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689c35f3a3b44fdba649851e048953fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample with down=0.35\n",
      "Best CV score 0.6196 for parameters: {'max_depth': 8, 'min_impurity_decrease': 0.0001, 'n_estimators': 150}\n",
      "Downsample with down=0.40\n",
      "Best CV score 0.6212 for parameters: {'max_depth': 9, 'min_impurity_decrease': 0.0001, 'n_estimators': 90}\n",
      "Downsample with down=0.45\n",
      "Best CV score 0.6226 for parameters: {'max_depth': 10, 'min_impurity_decrease': 1e-05, 'n_estimators': 100}\n",
      "Downsample with down=0.50\n",
      "Best CV score 0.6200 for parameters: {'max_depth': 11, 'min_impurity_decrease': 0.0001, 'n_estimators': 80}\n",
      "Downsample with down=0.55\n",
      "Best CV score 0.6169 for parameters: {'max_depth': 11, 'min_impurity_decrease': 1e-05, 'n_estimators': 110}\n",
      "Downsample with down=0.60\n",
      "Best CV score 0.6147 for parameters: {'max_depth': 13, 'min_impurity_decrease': 0.0001, 'n_estimators': 140}\n",
      "Downsample with down=0.65\n",
      "Best CV score 0.6138 for parameters: {'max_depth': 11, 'min_impurity_decrease': 1e-05, 'n_estimators': 110}\n",
      "Downsample with down=0.70\n",
      "Best CV score 0.6065 for parameters: {'max_depth': 12, 'min_impurity_decrease': 1e-05, 'n_estimators': 100}\n",
      "\n",
      "Best score for downsample is 0.6226 for down=0.44999999999999996 and params: {'max_depth': 10, 'min_impurity_decrease': 1e-05, 'n_estimators': 100}\n",
      "CPU times: user 55min 45s, sys: 11.3 s, total: 55min 56s\n",
      "Wall time: 56min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_tracker = []\n",
    "for down in tqdm(np.arange(0.35, 0.71, 0.05)):\n",
    "    print(f'Downsample with down={down:0.2f}')\n",
    "    score, params = global_param_tune_manual(X_train, y_train, RandomForestClassifier(), rf_params, down=down)\n",
    "    score_tracker.append((down, score, params))\n",
    "rf_down, rf_score, rf_params_down = sorted(score_tracker, key=lambda x: x[1], reverse=True)[0]\n",
    "X_train_down, y_train_down = downsample(X_train, y_train, rf_down)\n",
    "rf_clf_down = RandomForestClassifier(**rf_params_down).fit(X_train_down, y_train_down)\n",
    "cv_scores.loc['Downsampled Data', 'Random Forest'] = rf_score\n",
    "print(f'Best score for downsample is {rf_score:0.4f} for down={rf_down} and params: {rf_params_down}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902a63604ae2464881c70c06aab8eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsample with down=0.35\n",
      "Best CV score 0.5156 for parameters: {'estimator__C': 0.01, 'estimator__penalty': 'l1'}\n",
      "Downsample with down=0.40\n",
      "Best CV score 0.4992 for parameters: {'estimator__C': 0.01, 'estimator__penalty': 'l1'}\n",
      "Downsample with down=0.45\n",
      "Best CV score 0.4922 for parameters: {'estimator__C': 1, 'estimator__penalty': 'l1'}\n",
      "Downsample with down=0.50\n",
      "Best CV score 0.4803 for parameters: {'estimator__C': 0.1, 'estimator__penalty': 'l1'}\n",
      "Downsample with down=0.55\n",
      "Best CV score 0.4692 for parameters: {'estimator__C': 5, 'estimator__penalty': 'l1'}\n",
      "Downsample with down=0.60\n",
      "Best CV score 0.4530 for parameters: {'estimator__C': 1, 'estimator__penalty': 'l1'}\n",
      "Downsample with down=0.65\n",
      "Best CV score 0.4348 for parameters: {'estimator__C': 1, 'estimator__penalty': 'l2'}\n",
      "Downsample with down=0.70\n",
      "Best CV score 0.4202 for parameters: {'estimator__C': 5, 'estimator__penalty': 'l2'}\n",
      "\n",
      "Best score for downsample is 0.5155868890409149 for down=0.35 and params: {'estimator__C': 0.01, 'estimator__penalty': 'l1'}\n",
      "CPU times: user 1min 13s, sys: 53.9 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score_tracker = []\n",
    "for down in tqdm(np.arange(0.35, 0.71, 0.05)):\n",
    "    print(f'Downsample with down={down:0.2f}')\n",
    "    score, params = global_param_tune_manual(X_train, y_train, lr_pipe, lr_pipe_params, down=down)\n",
    "    score_tracker.append((down, score, params))\n",
    "lr_down, lr_score, lr_params_down = sorted(score_tracker, key=lambda x: x[1], reverse=True)[0]\n",
    "X_train_down, y_train_down = downsample(X_train, y_train, lr_down)\n",
    "lr_clf_down = lr_pipe.set_params(**lr_params_down).fit(X_train_down, y_train_down)\n",
    "cv_scores.loc['Downsampled Data', 'Logistic Regression'] = lr_score\n",
    "print(f'Best score for downsample is {lr_score} for down={lr_down} and params: {lr_params_down}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at CV scores from different models and different techniques used to deal with the imbalance of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Logistic Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Initial Data</td>\n",
       "      <td>0.563346</td>\n",
       "      <td>0.577298</td>\n",
       "      <td>0.32863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Upsampled Data</td>\n",
       "      <td>0.6042</td>\n",
       "      <td>0.621387</td>\n",
       "      <td>0.512716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Downsampled Data</td>\n",
       "      <td>0.606335</td>\n",
       "      <td>0.622593</td>\n",
       "      <td>0.515587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Decision Tree Random Forest Logistic Regression\n",
       "Initial Data          0.563346      0.577298             0.32863\n",
       "Upsampled Data          0.6042      0.621387            0.512716\n",
       "Downsampled Data      0.606335      0.622593            0.515587"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each technique we can see that Random Forest provided the highest CV score. No wonder here and we could see from the times spent for global parameters tuning that this improve in the accuracy comes with the cost of computational complexity. \n",
    "- Both upsampling and downsampling achieved a serious improvement on CV scores for every model tested\n",
    "- Downsampling was slightly better then upsampling for our task. It's not really that meaningfull because the difference with upsampling results well inside the possible error due to randomness of selections and so on. But in this case we suspect that the fact that we used only integer replicate parameter for upsampling let the technique down and we were able to find more optimal fraction parameter for downsample. But might be just no luck for upsample..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on cross validation scores we've got we should choose in favor of Random Forest model trained on downsampled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact we should test only the choosen model - Random Forest with downsample and check how it'll perform on the test set. But we'll test all other models we trained just for fun of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Initial_Dataset</th>\n",
       "      <th>Upsampled_Dataset</th>\n",
       "      <th>Downsampled_Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.323570</td>\n",
       "      <td>0.482187</td>\n",
       "      <td>0.482187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.585812</td>\n",
       "      <td>0.604146</td>\n",
       "      <td>0.621696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.599755</td>\n",
       "      <td>0.626484</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Initial_Dataset  Upsampled_Dataset  \\\n",
       "0  Logistic Regression         0.323570           0.482187   \n",
       "1        Decision Tree         0.585812           0.604146   \n",
       "2        Random Forest         0.599755           0.626484   \n",
       "\n",
       "   Downsampled_Dataset  \n",
       "0             0.482187  \n",
       "1             0.621696  \n",
       "2             0.627451  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_f1 = pd.DataFrame(columns=['Classifier', 'Initial_Dataset', 'Upsampled_Dataset', 'Downsampled_Dataset'])\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "test_results_f1.loc[test_results_f1.shape[0]] = [\n",
    "    'Logistic Regression',\n",
    "    f1_score(y_test, lr_pipe_clf.predict(X_test)),\n",
    "    f1_score(y_test, lr_clf_up.predict(X_test)),\n",
    "    f1_score(y_test, lr_clf_down.predict(X_test))\n",
    "]\n",
    "test_results_f1.loc[test_results_f1.shape[0]] = [\n",
    "    'Decision Tree',\n",
    "    f1_score(y_test, dt_clf.predict(X_test)),\n",
    "    f1_score(y_test, dt_clf_up.predict(X_test)),\n",
    "    f1_score(y_test, dt_clf_down.predict(X_test))\n",
    "]\n",
    "test_results_f1.loc[test_results_f1.shape[0]] = [\n",
    "    'Random Forest',\n",
    "    f1_score(y_test, rf_clf.predict(X_test)),\n",
    "    f1_score(y_test, rf_clf_up.predict(X_test)),\n",
    "    f1_score(y_test, rf_clf_down.predict(X_test))\n",
    "]\n",
    "test_results_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were lucky with the test set and got the scores for our prefered model even higher then CV score it had. It wasn't guaranteed that the best scores would be achieved by the best CV model but it actually was in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's take a look at another metric to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Initial_Dataset</th>\n",
       "      <th>Upsampled_Dataset</th>\n",
       "      <th>Downsampled_Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.590845</td>\n",
       "      <td>0.683645</td>\n",
       "      <td>0.683645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.724100</td>\n",
       "      <td>0.750866</td>\n",
       "      <td>0.772941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.724847</td>\n",
       "      <td>0.775911</td>\n",
       "      <td>0.773304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Initial_Dataset  Upsampled_Dataset  \\\n",
       "0  Logistic Regression         0.590845           0.683645   \n",
       "1        Decision Tree         0.724100           0.750866   \n",
       "2        Random Forest         0.724847           0.775911   \n",
       "\n",
       "   Downsampled_Dataset  \n",
       "0             0.683645  \n",
       "1             0.772941  \n",
       "2             0.773304  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_roc_auc = pd.DataFrame(columns=['Classifier', 'Initial_Dataset', 'Upsampled_Dataset', 'Downsampled_Dataset'])\n",
    "names = ['Logistic Regression', 'Decision Tree', 'Random Forest']\n",
    "test_results_roc_auc.loc[test_results_roc_auc.shape[0]] = [\n",
    "    'Logistic Regression',\n",
    "    roc_auc_score(y_test, lr_pipe_clf.predict(X_test)),\n",
    "    roc_auc_score(y_test, lr_clf_up.predict(X_test)),\n",
    "    roc_auc_score(y_test, lr_clf_down.predict(X_test))\n",
    "]\n",
    "test_results_roc_auc.loc[test_results_roc_auc.shape[0]] = [\n",
    "    'Decision Tree',\n",
    "    roc_auc_score(y_test, dt_clf.predict(X_test)),\n",
    "    roc_auc_score(y_test, dt_clf_up.predict(X_test)),\n",
    "    roc_auc_score(y_test, dt_clf_down.predict(X_test))\n",
    "]\n",
    "test_results_roc_auc.loc[test_results_roc_auc.shape[0]] = [\n",
    "    'Random Forest',\n",
    "    roc_auc_score(y_test, rf_clf.predict(X_test)),\n",
    "    roc_auc_score(y_test, rf_clf_up.predict(X_test)),\n",
    "    roc_auc_score(y_test, rf_clf_down.predict(X_test))\n",
    "]\n",
    "test_results_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well three leading models from f1-scoring table kept the leading positions with auc-roc scoring. Interesting that upsampled random forest beats the downsampled one by a bit but it means nothing for us, just that those models are very close in performance and we already did know that from our cross validation score table. Also we shouldn't be too impressed by the performance of the Downsampled Decision Tree model on the test set. Most likely it just got lucky with the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we were asked to build a model that could predict which of the Bank's customers are going to leave the Bank based on provided customer's data. We were not actually interested in the prediction of the loyal customers so the F1-score metric looks very appropriate choise to evaluate the performance of the models.\n",
    "<br><br>\n",
    "After some basic data preprocessing and setting aside the quarter of the data set as the test side we explored the perfomances of Logistic Regression, Decision Tree and Random Forest classifiers on the rest of the data. We used cross validation technique to tune the hyperparameters of the models, upsample and downsample methods of balancing the imbalanced data. <br>\n",
    "Based on crossvalidation scores we found that the upsampling/downsampling is crucial for performances of the models and that Random Forest models achived the best results on our data.\n",
    "<br>\n",
    "Thus we choose the Random Forest model trained on downsampled data as the model that could be used to predict whether a customer will leave the bank soon. <br>\n",
    "We tested the model on the test set and got the results: <br>\n",
    "F1-score = 0.6317 <br>\n",
    "AUC-ROC score = 0.7729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
